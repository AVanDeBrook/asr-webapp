9/13/22
-Created Vision Statement
-Created GitHub
-Created Discord
-Talked with Dr. Liu about vision statement and backlog items
-Set up meeting with group and Dr. Liu and Aaron

9/14/22
-Team meeting with Dr. Liu and Aaron about project goals and planning

9/15/22
-Met with Dr. Liu and Aaron about tasks for the semester
-Create a Sprint 1 goal decision
-Begin Learning and working through the NeMo Installation
-Download and Begin to understand Miconda
-Begin reading and understanding the Dive into Deep Learning Book

9/18/22
-Read Nvidia NeMo tutorial and began installation through google colabs
-Begin reading Dive into Deep Learning Chapter 2

9/20/22
-Read Dive into Deep Learning Chapter 2 and understand the code
-Run the code in Google Colab from Dive into Deep Learning Chapter 2

9/21/22
-Talk with Dr. Liu about the Google Maps Paid API issue and Java questions for Plotly Dash

9/22/22
-Desseminate information from Dr. Liu to group from email
-Fix backlog items
-Create weekly goals in text file for 9/30
-Plotly dash explanation on what Dr. Liu wants in Python

9/25/22 
-Worked with NeMo modeling in Google Colab to better understand ASR


9/27/22
-Mount Google Colab to Google Drive and talk with Aaron about what to present in Sprint 1

10/3/22
-Running an example NeMo model to train from a given language and transcribe
-Begin research into uncertainty models to work with NeMo

10/6/2022
-Work on Software Desgin Document 

10/8/2022
-Worked on creating Backlog Items for Sprint 2

10/10/2022
-Recieved Laptop from Aaron which has the graphical card ability to complete NVIDIA ASR Nueral Models

10/12/2022
-Worked on and Finished Sprint 1 Presentation Powerpoint

10/13/2022
-Presented Sprint 1 Presentation

10/14/2022 
-Mount Google Collab and run example scripts using ATC data
-Specificy requirements and tasks for next Sprint with team
-Log in to Laptop and Computer with NVIDIA graphics card which has the ability to complete NVIDIA Nueral models

10/18/2022
-Specify requirements and tasks for next sprint and beyond with Aaron

-10/22/2022
-Add the OneDrive PowerPoint to the GitHub in Documentation and Submit the Github link

10/25/2022
-Meet with Aaron to discuss more ASR related specifications and plan for training models

10/26/2022
-Set up GPU Laptop and move files so that the models are trained  
-Train models on the GPU laptop in LB 370

10/27/2022
-Found free API for flight tracking OpenSky

10/28/2022
-Work on System Test Plan Document

-11/1/2022 
-Work on System Test Plan Document
-Look into Word Error Rate functions to implement on the data for statistics from training

11/2/2022
-Fix and Submit System Test Plan Document
-Moving data on GPU computer to assist in running a Word Error Rate Script
-Assist Downloading NeMo and the GitHub onto Kira's computer to run future models

11/3/2022
-Look into the Python version of the OpenSky API
-Train a NeMo model on all of the data sets on the GPU laptop
-Get the .nemo file from the GPU laptop to the GitHub for Jakob to Test Word Error Rate Scripts found

11/7/2022
-SRS updates

11/8/2022
-Uninstall Windows update on GPU laptop causing possible NeMo failures
-Finish up SDS 
-Fix GPU laptop

11/10/22
-Do initial fixes on the Train_Finetune.py script on the GPU Laptop as it was not working previously

11/15/22
-Start working on Sprint 2 Powerpoint
-Talk with Aaron about issues relating to the GPU Laptop
-Obtained accesss to the Linux account with help of IT

11/16/22
-Continue working on Sprint 2 PowerPoint
-Attempt to fix issues with GPU laptop given Aaron's explaination

11/17/22
-Finish Sprint 2 PowerPoint and present Powerpoint in class

11/20/22
-Attempt some error fixes for the GPU laptop due to errors recieved when running trainfinetune.py

11/29/22
-Continue research and attempt implementation of error fixes of GPU laptop scripts

12/1/22
-Determine ways to recieve summative statistics while error fixes are resolved from communiction in the Nvidia NEMO GitHub
-Initialize Google Collab as a way to recieve these statistics and run tests while errors are resolved

12/2/22
-Attempt Audacity fixes for likely currupted audio files on GPU computer 
-Work within Google collab to train models and recieve Word Error Rate, Word Error rate per utterance and other statistics for the Jasper, Citrinet, and  Quarznet models 
-Understand and implement NeMo in google colab to run them and get data 

12/3/22
-Complete necessary changes as required by Aaron's comments in SRS and SDS and finalize the formatting for these documents along with submitting them on time

12/5/22
-Download ATCComp speech data to personal computer and upload the data to my personal google collab to use for training while the GPU Laptop issues are figured out
-Possible fix for GPU Lpatop is only using hiwire data to train, seems that ATCComp data may be currupted
-Create script for Google Colab to train models and use the ATCComp data to train these models to get more statistics

12/6/22
-Run training on GPU Laptop with just Hiwire to see if the error is from a currupted file in ATCComp0 as expecteed by the NVIDIA NeMo Github
-Start and Compelete the Sprint 3 Presentation
-Present the Sprint 3 Presentation

12/7/22
-Work on updating System Test Plan from Professor Akbas feedback

12/8/22
-Complete updates for System Test Plan and finalize System Test Plan to Submit

12/11/22
-Work on and finish the 3 miniute video

1/13/23
-Begin creation of final semester vision statement
-Work on Backlog for final semester

1/14/23
-Talk with Dr. Liu about specifics for project in final semester

1/17/23
-Talk with Aaron and Professor Pang about the project

1/19/23
-Begin creation of new model and work on training the new model 
-Update project vision Statement for the final semester and break down backlog to the different group members-
-Find substitution for ffmpeg file to convert sph file to wav file in atcc.py

1/22/23
-Finish updating project vision statement for semester

1/23/23
-Check project vision statement for final semester with Dr. Liu and Aaron
-Check with Aaron on the updates for atcc.py with the new sph to wav conversion 

1/24/22
-Submit project vision statement

1/25/22
-Found Github to try conversion between sph to wav

1/26/22
-Github solution to sph to wav conversion did not fix, attempt another solution using ffmpeg from original atcc.py
-Restructure and set up computer locations in LB 370 for maximum use for training

2/2/23
-Determine issue in preprocessing for Tensor = 1 error in Train_Finetune and understand Aaron's error fixes

2/6/23
-Begin Sprint 4 Powerpoint presentation and demo

2/7/23
-Complete Sprint 4 Powerpoint presentation and present the Powerpoint 
-Begin Sprint 5 goals
-Talk with Aaron about how to solve final issues with the Neural Modeling

2/9/23
-Implement Aaron fix for running models and run quartznet model on all of the datasets to include ATC_comp and Hiwire datasets to train the model and get an updated and imporved Word Error Rate

2/14/23
-Updated Professor Pang on the status of our project and goals for this sprint including the website updates and model updates
-Completed Peer Review for the previous sprint

2/16/23
-Created the script to train quartnet model on the GPU Laptop using Jakob's previous Citrinet script and began implementation of the Jasper script to train again
-Determined batch size must be 4 for GPU Laptop when training or memory issue discards training

2/17/23
-After seeing tokenizer Word Error Rate for new tokenizer training for Citrinet, look into changing the Word Error Rate script as the Word Error Rate still seems high
-Look into GPU Lapptop memory issue and realized it is not a memory issue but a randomness issue after consulting with Aaron, looking into possible fixes for issue

-2/20/23
-Begin quartznet script training on all the data using the created quartznet script to train all of the data as the memory issue should no longer be a problem.

2/23/23
-Update Professor Pang on the project with updated Word Error Rate number for the citrinet model and how the Word Error Rate scripts need to change as they are not giving accurate results
-Look into changing the Word Error Rate Scripts with Jakob to get better statistics for the next presentation
-Get Jakob and Tyler to begin creating the class for the integration of training data output and website
-Created a try catch for the word error rate script to use any model and get th results

2/24/23
-Add the created Quartznet and Jasper training models to the Github to try on the other computer as the Laptop is still having the random range error 
-Possible workaround is to limit the epochs instead of the batch size and get to checkpoints in training

2/27/23
-Implemented fix for 10 epochs on data in quartznet training due to the random number issue and determined this fix worked in editing the preprocessing files
-Began training on 100 epochs with quartznet after preprocessing training and fixing the batch size to possibly improve speed issue

2/28/23
-Explain fix for the quartznet and run tests to make sure the fix did not break anything
-Work on Word Error Rate Script to adjust for the quartznet and jasper model scripts

3/2/23
-Quartznet training finish work on editing word error rate to determine the word error rate or this script

3/7/23
-Work on System Test plan clarification and submission
-Finish up the word error rate script and run it to get updated word error rate for quartznet model
-Begin Jasper model script run
